# Configuration file for NLI models
# Contains hyperparameters for each model

# Common parameters
common:
  max_sequence_length: 100
  vocab_size: 20000
  batch_size: 64
  validation_split: 0.1
  early_stopping_patience: 3

# TF-IDF model
tfidf:
  max_features: [5000, 20000]
  ngram_range: [(1, 1), (1, 2)]
  learning_rate: [0.001, 0.0005, 0.0001]
  dropout_rate: [0.2, 0.3, 0.4]
  epochs: [10, 20, 30]

# Bi-LSTM with Attention model
bilstm_attention:
  epochs: [10, 50]
  embedding_dim: [100, 200]
  lstm_units: [64, 128]
  learning_rate: [0.001, 0.0005]

# Transformer model
transformer:
  epochs: [5, 15]
  embedding_dim: [128, 256]
  num_heads: [4, 8]
  learning_rate: [0.0001, 0.00005]

# BERT model
bert:
  epochs: [2, 5]
  learning_rate: [2e-5, 3e-5]
  max_sequence_length: [64, 128]
  batch_size: [16, 32]

# Decision Tree model
decision_tree:
  max_depth: [10, 20]
  min_samples_split: [2, 10]
  max_features: [0.3, 0.5]  # null means all features, float values are fractions of features
  tfidf_max_features: [5000, 10000]
